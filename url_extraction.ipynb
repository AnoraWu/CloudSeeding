{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://t.cn/zOJEz80'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import ast\n",
    "from urllib.request import urlopen\n",
    "\n",
    "def extract_words(url):\n",
    "    try:\n",
    "        html = requests.get(url)\n",
    "    except:\n",
    "        print(f\"Error opening url: {url}\")\n",
    "        return \"Error opening URL\"\n",
    "    \n",
    "    html.encoding = 'utf-8'\n",
    "    soup = BS(html.text, features=\"html.parser\")\n",
    "    text = soup.get_text(separator=\"\\n\").strip()\n",
    "    \n",
    "    # Try to find any specific 'desc' class divs\n",
    "    descs = soup.find_all('div', {'class': 'desc'})\n",
    "    \n",
    "    if descs:\n",
    "        for desc in descs:\n",
    "            if '此网页未在微博完成域名备案' in desc.text.strip():\n",
    "                # Follow the redirection URL and retry extracting text\n",
    "                redirect_url = descs[0].text.strip()\n",
    "                return extract_words(redirect_url)\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mextract_words\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[37], line 14\u001b[0m, in \u001b[0;36mextract_words\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening URL\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mhtml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m soup \u001b[38;5;241m=\u001b[39m BS(html\u001b[38;5;241m.\u001b[39mtext, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m text \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mget_text(separator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "print(extract_words(url))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
