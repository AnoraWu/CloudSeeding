{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import cpca\n",
    "import os\n",
    "import math\n",
    "os.chdir(\"/Users/anorawu/BFI Dropbox/Wanru Wu/Cloudseeding/data/抗议数据\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/anorawu/BFI Dropbox/Wanru Wu/Cloudseeding/data/抗议数据/RFA_protest3.csv\",encoding='utf-8')\n",
    "df = df[['adcode','location','size_level','year','month','day','citycode','省','市','区']]\n",
    "df.to_csv(\"/Users/anorawu/BFI Dropbox/Wanru Wu/Cloudseeding/data/抗议数据/RFA_protest3_cropped.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_stata(\"cloudseeding.dta\")\n",
    "df[\"district\"] = df['prov'] + df['city'] + df['county']\n",
    "df_adcode = cpca.transform(df[\"district\"])\n",
    "df['adcode'] = df_adcode['adcode']\n",
    "df.to_csv(\"cloudseeding_adcode.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_stata(\"Meteorological.dta\")\n",
    "df[\"district\"] = df['prov'] + df['city'] + df['county']\n",
    "df_adcode = cpca.transform(df[\"district\"])\n",
    "df['adcode'] = df_adcode['adcode']\n",
    "df.to_csv(\"meteorological_adcode.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_stata(\"final_panel_newweibo.dta\")\n",
    "df = df.sort_values(by=['adcode', 'date']).reset_index()\n",
    "df[\"day\"] = df.groupby(\"adcode\").cumcount()\n",
    "df['event'] = 0\n",
    "\n",
    "# Identify events (first protest and subsequent protests >= 3 months apart)\n",
    "for ad, ad_df in df.groupby('adcode'):\n",
    "    protest_dates = ad_df.loc[ad_df['n_prt_weibo'] > 0, 'day'].sort_values().tolist()\n",
    "    last_event = None\n",
    "    \n",
    "    for protest_date in protest_dates:\n",
    "        if last_event is None or (protest_date - last_event) >= 45:\n",
    "            df.loc[(df['adcode'] == int(ad)) & (df['day'] == protest_date),'event'] = 1\n",
    "            last_event = protest_date\n",
    "\n",
    "index_list = df.loc[df['event']==1,'index'].tolist()\n",
    "df['to_day']=None\n",
    "for index in index_list:\n",
    "    for i in range(-22,23):\n",
    "        if not (index+i<0) or (index+i>len(df)):\n",
    "            df.loc[df['index']==index+i,'to_day'] = i\n",
    "\n",
    "df.to_csv('eventstudy_weibo_county.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_stata(\"final_panel_newweibo.dta\")\n",
    "df = df.sort_values(by=['adcode', 'date']).reset_index()\n",
    "df[\"day\"] = df.groupby(\"adcode\").cumcount()\n",
    "df['event'] = 0\n",
    "\n",
    "# Identify events (first protest and subsequent protests >= 3 months apart)\n",
    "for ad, ad_df in df.groupby('adcode'):\n",
    "    protest_dates = ad_df.loc[ad_df['n_prt_rfa'] > 0, 'day'].sort_values().tolist()\n",
    "    last_event = None\n",
    "    \n",
    "    for protest_date in protest_dates:\n",
    "        if last_event is None or (protest_date - last_event) >= 45:\n",
    "            df.loc[(df['adcode'] == int(ad)) & (df['day'] == protest_date),'event'] = 1\n",
    "            last_event = protest_date\n",
    "\n",
    "index_list = df.loc[df['event']==1,'index'].tolist()\n",
    "df['to_day']=None\n",
    "for index in index_list:\n",
    "    for i in range(-22,23):\n",
    "        if not (index+i<0) or (index+i>len(df)):\n",
    "            df.loc[df['index']==index+i,'to_day'] = i\n",
    "\n",
    "df.to_csv('eventstudy_rfa_county.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_stata(\"eventstudy_city.dta\")\n",
    "df = df.sort_values(by=['citycode', 'date']).reset_index()\n",
    "df[\"day\"] = df.groupby(\"citycode\").cumcount()\n",
    "df['event'] = 0\n",
    "\n",
    "# Identify events (first protest and subsequent protests >= 3 months apart)\n",
    "for city, city_df in df.groupby('citycode'):\n",
    "    protest_dates = city_df.loc[city_df['n_prt_weibo'] > 0, 'day'].sort_values().tolist()\n",
    "    last_event = None\n",
    "    \n",
    "    for protest_date in protest_dates:\n",
    "        if last_event is None or (protest_date - last_event) >= 45:\n",
    "            df.loc[(df['citycode'] == int(city)) & (df['day'] == protest_date),'event'] = 1\n",
    "            last_event = protest_date\n",
    "\n",
    "index_list = df.loc[df['event']==1,'index'].tolist()\n",
    "df['to_day']=None\n",
    "for index in index_list:\n",
    "    for i in range(-22,23):\n",
    "        if not (index+i<0) or (index+i>len(df)):\n",
    "            df.loc[df['index']==index+i,'to_day'] = i\n",
    "\n",
    "df.to_csv('eventstudy_weibo_city.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_stata(\"eventstudy_city.dta\")\n",
    "df = df.sort_values(by=['citycode', 'date']).reset_index()\n",
    "df[\"day\"] = df.groupby(\"citycode\").cumcount()\n",
    "df['event'] = 0\n",
    "\n",
    "# Identify events (first protest and subsequent protests >= 3 months apart)\n",
    "for city, city_df in df.groupby('citycode'):\n",
    "    protest_dates = city_df.loc[city_df['n_prt_rfa'] > 0, 'day'].sort_values().tolist()\n",
    "    last_event = None\n",
    "    \n",
    "    for protest_date in protest_dates:\n",
    "        if last_event is None or (protest_date - last_event) >= 45:\n",
    "            df.loc[(df['citycode'] == int(city)) & (df['day'] == protest_date),'event'] = 1\n",
    "            last_event = protest_date\n",
    "\n",
    "index_list = df.loc[df['event']==1,'index'].tolist()\n",
    "df['to_day']=None\n",
    "for index in index_list:\n",
    "    for i in range(-22,23):\n",
    "        if not (index+i<0) or (index+i>len(df)):\n",
    "            df.loc[df['index']==index+i,'to_day'] = i\n",
    "\n",
    "df.to_csv('eventstudy_rfa_city.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5h/rb902v091ys_0c5x0jt8sbjw0000gp/T/ipykernel_76345/3249019293.py:20: InvalidColumnName: \n",
      "Not all pandas column names were valid Stata variable names.\n",
      "The following replacements have been made:\n",
      "\n",
      "    Unnamed: 0   ->   Unnamed__0\n",
      "\n",
      "If this is not what you expect, please make sure you have Stata-compliant\n",
      "column names in your DataFrame (strings only, max 32 characters, only\n",
      "alphanumerics and underscores, no Stata reserved words)\n",
      "\n",
      "  df_final.to_stata(\"test1.dta\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('eventstudy_weibo_city.csv')\n",
    "\n",
    "# Identify unique events and assign an event ID \n",
    "df_list = []\n",
    "for city, city_df in df.groupby('citycode'):\n",
    "    city_df['event_id'] = (city_df['event'] == 1).cumsum()\n",
    "    city_df.loc[df['event'] == 0, 'event_id'] = None   \n",
    "    num = city_df['event_id'].max()\n",
    "\n",
    "    if math.isnan(num):\n",
    "        city_df['num'] = 0\n",
    "        df_list.append(city_df)\n",
    "    else:\n",
    "        for i in range(0,int(num)):\n",
    "            city_df_temp = city_df.copy()\n",
    "            city_df_temp['num'] = i+1\n",
    "            df_list.append(city_df_temp)\n",
    "\n",
    "df_final = pd.concat(df_list)\n",
    "df_final.to_stata('temp_event.dta')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mint\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mint\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_id\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mint\u001b[39m(num):\n\u001b[0;32m----> 4\u001b[0m             \u001b[43mdf_final\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mevent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m df_final\u001b[38;5;241m.\u001b[39mto_stata(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest2.dta\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cloud/lib/python3.12/site-packages/pandas/core/indexing.py:911\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    910\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m--> 911\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cloud/lib/python3.12/site-packages/pandas/core/indexing.py:1942\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1939\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[1;32m   1940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[1;32m   1941\u001b[0m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[0;32m-> 1942\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_split_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1943\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1944\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cloud/lib/python3.12/site-packages/pandas/core/indexing.py:2035\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   2032\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2033\u001b[0m     \u001b[38;5;66;03m# scalar value\u001b[39;00m\n\u001b[1;32m   2034\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m loc \u001b[38;5;129;01min\u001b[39;00m ilocs:\n\u001b[0;32m-> 2035\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_single_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpi\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cloud/lib/python3.12/site-packages/pandas/core/indexing.py:2175\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_single_column\u001b[0;34m(self, loc, value, plane_indexer)\u001b[0m\n\u001b[1;32m   2165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mvoid:\n\u001b[1;32m   2166\u001b[0m         \u001b[38;5;66;03m# This means we're expanding, with multiple columns, e.g.\u001b[39;00m\n\u001b[1;32m   2167\u001b[0m         \u001b[38;5;66;03m#     df = pd.DataFrame({'A': [1,2,3], 'B': [4,5,6]})\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2170\u001b[0m         \u001b[38;5;66;03m# Here, we replace those temporary `np.void` columns with\u001b[39;00m\n\u001b[1;32m   2171\u001b[0m         \u001b[38;5;66;03m# columns of the appropriate dtype, based on `value`.\u001b[39;00m\n\u001b[1;32m   2172\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc[:, loc] \u001b[38;5;241m=\u001b[39m construct_1d_array_from_inferred_fill_value(\n\u001b[1;32m   2173\u001b[0m             value, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   2174\u001b[0m         )\n\u001b[0;32m-> 2175\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_setitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplane_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cloud/lib/python3.12/site-packages/pandas/core/internals/managers.py:1337\u001b[0m, in \u001b[0;36mBlockManager.column_setitem\u001b[0;34m(self, loc, idx, value, inplace_only)\u001b[0m\n\u001b[1;32m   1335\u001b[0m     col_mgr\u001b[38;5;241m.\u001b[39msetitem_inplace(idx, value)\n\u001b[1;32m   1336\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1337\u001b[0m     new_mgr \u001b[38;5;241m=\u001b[39m \u001b[43mcol_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miset(loc, new_mgr\u001b[38;5;241m.\u001b[39m_block\u001b[38;5;241m.\u001b[39mvalues, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m needs_to_warn:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cloud/lib/python3.12/site-packages/pandas/core/internals/managers.py:415\u001b[0m, in \u001b[0;36mBaseBlockManager.setitem\u001b[0;34m(self, indexer, value, warn)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;66;03m# No need to split if we either set all columns or on a single block\u001b[39;00m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;66;03m# manager\u001b[39;00m\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msetitem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cloud/lib/python3.12/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for index,row in df_final.iterrows():\n",
    "    if int(row['event']) == 1:\n",
    "        if int(row['event_id']) != int(num):\n",
    "            df_final.loc[index,'event'] = 0\n",
    "df_final.to_stata('test2.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5h/rb902v091ys_0c5x0jt8sbjw0000gp/T/ipykernel_11317/258707157.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time1'] = df1['time1'].astype(str)\n",
      "/var/folders/5h/rb902v091ys_0c5x0jt8sbjw0000gp/T/ipykernel_11317/258707157.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time1'] = df1['time1'].str.replace(\"[\", \"\")\n",
      "/var/folders/5h/rb902v091ys_0c5x0jt8sbjw0000gp/T/ipykernel_11317/258707157.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time1'] = df1['time1'].str.replace(\"]\", \"\")\n",
      "/var/folders/5h/rb902v091ys_0c5x0jt8sbjw0000gp/T/ipykernel_11317/258707157.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time1'] = df1['time1'].str.replace(\"，\", \",\")\n",
      "/var/folders/5h/rb902v091ys_0c5x0jt8sbjw0000gp/T/ipykernel_11317/258707157.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time1'] = df1['time1'].str.replace(\"、\", \",\")\n",
      "/var/folders/5h/rb902v091ys_0c5x0jt8sbjw0000gp/T/ipykernel_11317/258707157.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time1'] = df1['time1'].str.replace(\"；\", \",\")\n",
      "/var/folders/5h/rb902v091ys_0c5x0jt8sbjw0000gp/T/ipykernel_11317/258707157.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time1'] = df1['time1'].str.replace(\";\", \",\")\n",
      "/var/folders/5h/rb902v091ys_0c5x0jt8sbjw0000gp/T/ipykernel_11317/258707157.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time1'] = df1['time1'].str.split(',')\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "\n",
    "folder_dir  = r\"/Users/anorawu/BFI Dropbox/Wanru Wu/Cloudseeding/data/抗议数据\"\n",
    "input_file   = rf\"{folder_dir}/extracted_weibo_time2.csv\"\n",
    "output_file = rf\"{folder_dir}/extracted_weibo_time3.csv\"\n",
    "\n",
    "df = pd.read_csv(input_file, encoding=\"utf-8\",dtype={\"省\":\"string\",\"市\":\"string\",\"区\":\"string\"},index_col=False )\n",
    "\n",
    "df['time2'] = df['time2'].astype(str)\n",
    "df['time2'] = df['time2'].str.replace(\"[\", \"\")\n",
    "df['time2'] = df['time2'].str.replace(\"]\", \"\")\n",
    "df['time2'] = df['time2'].str.replace(\"，\", \",\")\n",
    "df['time2'] = df['time2'].str.replace(\"、\", \",\")\n",
    "df['time2'] = df['time2'].str.replace(\"；\", \",\")\n",
    "df['time2'] = df['time2'].str.replace(\";\", \",\")\n",
    "df['time2'] = df['time2'].str.split(',')\n",
    "\n",
    "df = df.explode('time2', ignore_index=True)\n",
    "df[['month1','year1','day1']] = None\n",
    "df[['month1','year1','day1']] = df[['month1','year1','day1']].astype(str)\n",
    "df['month1'] = df['time2'].str.extract(r'(\\d+)(?=月)')\n",
    "df['year1'] = df['time2'].str.extract(r'(\\d+)(?=年)')\n",
    "df['day1'] = df['time2'].str.extract(r'(\\d+)(?=日)')\n",
    "df.loc[df['day1'].isna(), 'day1'] = df['time2'].str.extract(r'(\\d+)(?=号)')\n",
    "\n",
    "df1= df.loc[(df['year1'].isna()) | (df['month1'].isna()) | (df['day1'].isna())]\n",
    "df1['time1'] = df1['time1'].astype(str)\n",
    "df1['time1'] = df1['time1'].str.replace(\"[\", \"\")\n",
    "df1['time1'] = df1['time1'].str.replace(\"]\", \"\")\n",
    "df1['time1'] = df1['time1'].str.replace(\"，\", \",\")\n",
    "df1['time1'] = df1['time1'].str.replace(\"、\", \",\")\n",
    "df1['time1'] = df1['time1'].str.replace(\"；\", \",\")\n",
    "df1['time1'] = df1['time1'].str.replace(\";\", \",\")\n",
    "df1['time1'] = df1['time1'].str.split(',')\n",
    "\n",
    "df1 = df1.explode('time1', ignore_index=True)\n",
    "df1 = df1[df1['time1'].str.contains(r'[号日]', na=False)]\n",
    "\n",
    "df1.loc[df1['month1'].isna(), 'month1'] = df1['time1'].str.extract(r'(\\d+)(?=月)')[0]\n",
    "df1.loc[df1['year1'].isna(), 'year1'] = df1['time1'].str.extract(r'(\\d+)(?=年)')[0]\n",
    "df1.loc[df1['day1'].isna(), 'day1'] = df1['time1'].str.extract(r'(\\d+)(?=日)')[0]\n",
    "df1.loc[df1['day1'].isna(), 'day1'] = df1['time1'].str.extract(r'(\\d+)(?=号)')[0]\n",
    "\n",
    "# replace year1 = year if year1.isna() or if year1<2010\n",
    "df1['year1'] = df1['year1'].astype('Int64')\n",
    "df1['month1'] = df1['month1'].astype('Int64')\n",
    "df1.loc[df1['year1'].isna() | (df1['year1'] < 2010), 'year1'] = df1['year']\n",
    "df1.loc[df1['month1'].isna(), 'month1'] = df1['month']\n",
    "\n",
    "df2 = pd.concat([df,df1])\n",
    "df2.dropna(subset=['year1', 'month1','day1'],inplace=True)\n",
    "df2.drop_duplicates(subset=['posts','year1', 'month1','day1'],inplace=True)\n",
    "df2.to_csv('cleaned_time_weibo_protests.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
