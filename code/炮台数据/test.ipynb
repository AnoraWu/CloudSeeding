{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "from geopy import distance\n",
    "import calendar\n",
    "\n",
    "os.chdir(\"/Users/anorawu/Documents/GitHub/CloudSeeding/data/炮台数据\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fort_data = pd.read_csv(\"cleaned_炮台数据.csv\")\n",
    "fort_data = fort_data[fort_data['year']<=2022]\n",
    "\n",
    "lon_max = fort_data['longitude'].max() + 1\n",
    "lon_min = fort_data['longitude'].min() - 1\n",
    "lat_max = fort_data['latitude'].max() + 1\n",
    "lat_min = fort_data['latitude'].min() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fort_points = fort_data[['index','longitude','latitude']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_data = pd.read_stata(\"weatherstation_2010_2022.dta\")\n",
    "rain_data = rain_data.dropna(subset=['Lat', 'Lon'])\n",
    "rain_data = rain_data[(rain_data['Lat'] >= lat_min) & (rain_data['Lat'] <= lat_max)]\n",
    "rain_data = rain_data[(rain_data['Lon'] >= lon_min) & (rain_data['Lon'] <= lon_max)]\n",
    "\n",
    "rain_points = rain_data[['StationId','Lon','Lat']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_gdf = gpd.GeoDataFrame(\n",
    "    rain_points,\n",
    "    geometry=gpd.points_from_xy(rain_points['Lon'], rain_points['Lat']),\n",
    "    crs=\"EPSG:4326\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fort_gdf = gpd.GeoDataFrame(\n",
    "    fort_points,\n",
    "    geometry=gpd.points_from_xy(fort_points['longitude'], fort_points['latitude']),\n",
    "    crs=\"EPSG:4326\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = 0.5\n",
    "dic = {}\n",
    "\n",
    "for _, fort_point in fort_gdf.iterrows():  \n",
    "    buffer = fort_point.geometry.buffer(radius)  \n",
    "    \n",
    "    pts_inside = rain_gdf[rain_gdf.within(buffer)]\n",
    "    \n",
    "    pts_dic = {}\n",
    "    for _, row in pts_inside.iterrows():\n",
    "        dist = distance.distance(\n",
    "            (fort_point.geometry.y, fort_point.geometry.x),  \n",
    "            (row['Lat'], row['Lon'])                        \n",
    "        ).km\n",
    "        pts_dic[row['StationId']] = dist\n",
    "    \n",
    "    sorted_pts = sorted(pts_dic.items(), key=lambda item: item[1])[:2]\n",
    "    \n",
    "    dic[fort_point['index']] = sorted_pts  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Alti', 'EVP', 'GST_Avg', 'GST_Max', 'GST_Min', 'PRE_Max_1h',\n",
    "       'PRE_Time_2008', 'PRE_Time_0820', 'PRE_Time_2020', 'PRS_Avg', 'PRS_Max',\n",
    "       'PRS_Min', 'RHU_Avg', 'RHU_Min', 'SSH', 'TEM_Avg', 'TEM_Max', 'TEM_Min',\n",
    "       'WIN_S_2mi_Avg', 'WIN_S_10mi_Avg', 'WIN_D_S_Max', 'WIN_S_Max',\n",
    "       'WIN_D_INST_Max', 'WIN_S_Inst_Max']\n",
    "\n",
    "for year in range(2011,2023):\n",
    "    for month in range(1,13):\n",
    "        days_in_month = calendar.monthrange(year, month)[1]\n",
    "        for day in range(1,days_in_month+1):\n",
    "            for idx, fort_point in fort_points:\n",
    "                pts_list = dic[fort_point['index']]\n",
    "\n",
    "                weight_sum = 0\n",
    "                list_of_data = []\n",
    "                for pts in pts_list:\n",
    "                    rain_id,dist = pts\n",
    "                    # Make a copy of the filtered rows\n",
    "                    filtered_row = rain_data[\n",
    "                        (rain_data['Year'] == year) & \n",
    "                        (rain_data['Mon'] == month) & \n",
    "                        (rain_data['Day'] == day) & \n",
    "                        (rain_data['StationId'] == rain_id)\n",
    "                    ].copy()  \n",
    "\n",
    "                    filtered_row[columns] = filtered_row[columns] * 1 / (dist**2)\n",
    "                    list_of_data.append(filtered_row)\n",
    "                    weight_sum += 1/(dist**2) \n",
    "                \n",
    "                concat_data = pd.concat(list_of_data)\n",
    "                concat_data_sum = concat_data[columns].sum(min_count=4)\n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_data['EVP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate a random DataFrame\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Create random data\n",
    "n_rows = 10\n",
    "data = {\n",
    "    'Year': np.random.randint(2011, 2023, size=n_rows),\n",
    "    'Mon': np.random.randint(1, 13, size=n_rows),\n",
    "    'Day': np.random.randint(1, 29, size=n_rows),  # Assume 28 days max for simplicity\n",
    "    'Lat': np.random.uniform(-90, 90, size=n_rows),\n",
    "    'Lon': np.random.uniform(-180, 180, size=n_rows),\n",
    "    'Rainfall': np.random.uniform(0, 100, size=n_rows),  # Random rainfall data\n",
    "    'Temperature': np.random.uniform(-30, 50, size=n_rows),  # Random temperature data\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "test = pd.DataFrame(data)\n",
    "concat_test = pd.concat([test,test])\n",
    "concat_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[list(test['Year'].nlargest(25).index)]\n",
    "test[\"Day\"].notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = pd.DataFrame({\n",
    "    'latitude': [10.1, 10.2, 10.3, 10.4],\n",
    "    'longitude': [20.1, 20.2, 20.3, 20.4],\n",
    "    'value': [100, 200, 300, 400]\n",
    "})\n",
    "\n",
    "# Coordinate list\n",
    "coordinates = [(20.1, 10.1), (20.1, 10.2), (20.2, 10.1), (20.2, 10.2)]\n",
    "\n",
    "# Extract rows where 'latitude' and 'longitude' match the coordinates\n",
    "filtered_data = data[data[['longitude', 'latitude']].apply(tuple, axis=1).isin(coordinates)]\n",
    "\n",
    "# Display result\n",
    "filtered_data['test'] = \"test\"\n",
    "print(filtered_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "from geopy import distance\n",
    "import calendar\n",
    "\n",
    "# 设置路径和读取数据\n",
    "os.chdir(\"/Users/anorawu/Documents/GitHub/CloudSeeding/data/炮台数据\")\n",
    "\n",
    "# 加载炮台数据\n",
    "fort_data = pd.read_csv(\"cleaned_炮台数据.csv\")\n",
    "\n",
    "lon_max = fort_data['longitude'].max() + 1\n",
    "lon_min = fort_data['longitude'].min() - 1\n",
    "lat_max = fort_data['latitude'].max() + 1\n",
    "lat_min = fort_data['latitude'].min() - 1\n",
    "\n",
    "fort_points = fort_data[['longitude', 'latitude']].drop_duplicates()\n",
    "\n",
    "# 加载气象站数据\n",
    "rain_data = pd.read_stata(\"weatherstation_2010_2022.dta\")\n",
    "rain_data = rain_data.dropna(subset=['Lat', 'Lon'])\n",
    "rain_data = rain_data[(rain_data['Lat'] >= lat_min) & (rain_data['Lat'] <= lat_max)]\n",
    "rain_data = rain_data[(rain_data['Lon'] >= lon_min) & (rain_data['Lon'] <= lon_max)]\n",
    "\n",
    "rain_points = rain_data[['StationId', 'Lon', 'Lat']].drop_duplicates()\n",
    "\n",
    "# 转换为GeoDataFrame\n",
    "rain_gdf = gpd.GeoDataFrame(\n",
    "    rain_points,\n",
    "    geometry=gpd.points_from_xy(rain_points['Lon'], rain_points['Lat']),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "fort_gdf = gpd.GeoDataFrame(\n",
    "    fort_points,\n",
    "    geometry=gpd.points_from_xy(fort_points['longitude'], fort_points['latitude']),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "\n",
    "radius = 0.5\n",
    "counts = []\n",
    "count_zero = 0\n",
    "count_one = 0\n",
    "count_two = 0\n",
    "count_three = 0\n",
    "count_four = 0\n",
    "count_five = 0\n",
    "count_enough = 0\n",
    "\n",
    "for _, fort_point in fort_gdf.iterrows():  \n",
    "    buffer = fort_point.geometry.buffer(radius)  \n",
    "    \n",
    "    # Correct use of 'within' and counting True values\n",
    "    count = rain_gdf['geometry'].within(buffer).sum()  \n",
    "    if count == 0:\n",
    "        count_zero += 1\n",
    "    if count == 1:\n",
    "        count_one += 1\n",
    "    if count == 2:\n",
    "        count_two += 1\n",
    "    if count == 3:\n",
    "        count_three += 1\n",
    "    if count == 4:\n",
    "        count_four += 1\n",
    "    if count == 5:\n",
    "        count_five += 1\n",
    "    if count > 5:\n",
    "        count_enough += 1                        \n",
    "    counts.append(count)\n",
    "        \n",
    "# Final ratio calculation\n",
    "print(sum(counts) / len(fort_gdf))\n",
    "print(\"zero:\",count_zero)\n",
    "print(\"one:\",count_one)\n",
    "print(\"two:\",count_two)\n",
    "print(\"three:\",count_three)\n",
    "print(\"four:\",count_four)\n",
    "print(\"five:\",count_five)\n",
    "print(\">five\", count_enough)\n",
    "print(len(counts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fort_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_complete_temp = np.arange(18,55,0.5).tolist()\n",
    "lon_complete_temp = np.arange(73.125, 135, 0.625).tolist()\n",
    "# Remove useless digits\n",
    "lat_complete_merra = [int(num) if num == int(num) else num for num in lat_complete_temp]\n",
    "lon_complete_merra = [int(num) if num == int(num) else num for num in lon_complete_temp]\n",
    "print(lon_complete_merra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script Name: cloud_checking.py\n",
    "Author: Wanru Wu\n",
    "Date: Jan 6, 2025\n",
    "Purpose: Check the completeness of cloud data \n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import calendar\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    ### Set directories\n",
    "    data_dir = \"/Users/anorawu/BFI Dropbox/Wanru Wu/Cloudseeding/data\"\n",
    "\n",
    "    # cloud thickness and fraction\n",
    "    modis_dir = f\"{data_dir}/MODIS\"\n",
    "    # weather station statistics\n",
    "    weather_station_dir = f\"{data_dir}/weatherstation_2010_2022.dta\"\n",
    "    # air, ice, and liquid\n",
    "    merra_dir = f\"{data_dir}/MERRA_levmean\" \n",
    "\n",
    "    ### If true, then check the data\n",
    "    check_modis = True\n",
    "    check_weather_station = True\n",
    "    check_merra = True\n",
    "\n",
    "    ### Check merra data\n",
    "    if check_merra:\n",
    "        print(\"\\n\\n\\n check merra \\n\\n\\n\")\n",
    "\n",
    "        lat_complete_temp = np.arange(18,55,0.5).tolist()\n",
    "        lon_complete_temp = np.arange(73.125, 135, 0.625).tolist()\n",
    "        # Remove useless digits\n",
    "        lat_complete_merra = [int(num) if num == int(num) else num for num in lat_complete_temp]\n",
    "        lon_complete_merra = [int(num) if num == int(num) else num for num in lon_complete_temp]\n",
    "        try:\n",
    "            for year in range(2010, 2024):\n",
    "                for month in range(1, 13):\n",
    "                    # Get the data frame for the month and year\n",
    "                    file_path = f\"{merra_dir}/merra{year}{month:02}.dta\"\n",
    "                    temp_df   = pd.read_stata(file_path)\n",
    "                    pd.set_option('display.float_format', '{:.10f}'.format)\n",
    "\n",
    "                    # Check if dates are complete\n",
    "                    days_in_month = range(1,calendar.monthrange(year, month)[1]+1)\n",
    "\n",
    "                    # Extract all dates\n",
    "                    date_list     = list(temp_df['day'].unique())\n",
    "\n",
    "                    # Check if all dates are available\n",
    "                    missing_days = [item for item in days_in_month if item not in date_list]\n",
    "                    if missing_days:\n",
    "                        print(f\"In year {year} and month {month}, the missing days are\", missing_days)\n",
    "                    else:\n",
    "                        print(f\"In year {year} and month {month}, days are complete\")\n",
    "\n",
    "                    # Check if latitudes and longitudes are complete\n",
    "                    print(temp_df['lon'].unique())\n",
    "                    lon_list = [x for x in temp_df['lon'].unique()]\n",
    "                    lat_list = [x for x in temp_df['lat'].unique()]\n",
    "\n",
    "\n",
    "                    missing_lat = [item for item in lat_complete_merra if item not in lat_list]\n",
    "                    missing_lon = [item for item in lon_complete_merra if item not in lon_list]\n",
    "        except Exception as e:\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directories\n",
    "data_dir = r\"/Users/anorawu/BFI Dropbox/Wanru Wu/Cloudseeding/data\"\n",
    "\n",
    "# cloud thickness and fraction\n",
    "modis_dir = f\"{data_dir}/MODIS\"\n",
    "output_file = f\"{data_dir}/data/炮台数据/processed_cloud_data_1.csv\"\n",
    "\n",
    "# Load points data\n",
    "df_pt = pd.read_csv(f\"{data_dir}/炮台数据/cleaned_炮台数据.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_pt))\n",
    "print(len(df_pt[['latitude','longitude','operation_year','operation_month','operation_day']].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a simple DataFrame\n",
    "data = {\n",
    "    \"value\": [10, 20, 30],\n",
    "    \"weight\": [1, 2, 3]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(np.average(data[\"value\"],weights=data[\"weight\"]))\n",
    "print(140/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "print(cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (.0094259816624*0.00031956594819740493 + .0766037718492*0.00018513082147373537 + \n",
    "0*0.00014412843187886127 + .001419354807*0.00010825518228461739) / (0.00031956594819740493+0.00018513082147373537+0.00014412843187886127+0.00010825518228461739)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "### Set directories\n",
    "data_dir = \"/Users/anorawu/BFI Dropbox/Wanru Wu/Cloudseeding/data\"\n",
    "\n",
    "# cloud thickness and fraction\n",
    "modis_dir = f\"{data_dir}/MODIS\"\n",
    "# weather station statistics\n",
    "weather_station_dir = f\"{data_dir}/weatherstation_2010_2022.dta\"\n",
    "# air, ice, and liquid\n",
    "merra_dir = f\"{data_dir}/MERRA_levmean\" \n",
    "\n",
    "### If true, then check the data\n",
    "check_modis = False\n",
    "check_weather_station = True\n",
    "check_merra = False\n",
    "check_era5 = False\n",
    "\n",
    "### Check weather station data \n",
    "if check_weather_station:\n",
    "\n",
    "    print(\"\\n\\n\\n check weather station \\n\\n\\n\")\n",
    "\n",
    "    # Check if there are any missing days for each StationId\n",
    "    def check_continuity_with_gaps(group):\n",
    "        first_date = group['Date'].min()\n",
    "        full_date_range = pd.date_range(start=first_date, end=group['Date'].max())\n",
    "        actual_dates = group['Date']\n",
    "        missing_dates = set(full_date_range) - set(actual_dates)\n",
    "        print(missing_dates)\n",
    "        if not missing_dates:\n",
    "            return \"Continuous\"\n",
    "        else:\n",
    "            return f\"Missing Dates: {sorted(missing_dates)}\"\n",
    "\n",
    "    try:\n",
    "        # Get the data frame\n",
    "        temp_df = pd.read_stata(weather_station_dir)\n",
    "        temp_df = temp_df[temp_df['StationId']!=999999.0]\n",
    "\n",
    "        # # Create a Date column for easier processing\n",
    "        temp_df['Date'] = pd.to_datetime(temp_df['Year', 'Mon', 'Day']])\n",
    "        # temp_df = temp_df.sort_values(by=['StationId', 'Date']).reset_index(drop=True)\n",
    "\n",
    "        # # Apply the function and summarize results\n",
    "        # continuity_summary = temp_df.groupby('StationId').apply(check_continuity_with_gaps)\n",
    "\n",
    "        # # Print the results\n",
    "        # for station_id, result in continuity_summary.items():\n",
    "        #     if result != \"Continuous\":\n",
    "        #         print(f\"StationId: {station_id}, Status: {result}\")     \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>operation_year</th>\n",
       "      <th>operation_month</th>\n",
       "      <th>operation_day</th>\n",
       "      <th>first_operation_date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>wt_cloud_optical_thickness</th>\n",
       "      <th>wt_cloud_mask_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112.499268</td>\n",
       "      <td>35.077713</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.887183</td>\n",
       "      <td>0.464000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112.499268</td>\n",
       "      <td>35.077713</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8.694333</td>\n",
       "      <td>0.972531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112.499268</td>\n",
       "      <td>35.077713</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8.330209</td>\n",
       "      <td>0.998417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>112.499268</td>\n",
       "      <td>35.077713</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7.004502</td>\n",
       "      <td>0.999176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112.499268</td>\n",
       "      <td>35.077713</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10.417659</td>\n",
       "      <td>0.997777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12377403</th>\n",
       "      <td>117.651801</td>\n",
       "      <td>27.569128</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>2019-03-21</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>0.372230</td>\n",
       "      <td>0.180912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12377404</th>\n",
       "      <td>117.651801</td>\n",
       "      <td>27.569128</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>2019-03-21</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>0.049143</td>\n",
       "      <td>0.001069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12377405</th>\n",
       "      <td>117.651801</td>\n",
       "      <td>27.569128</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>2019-03-21</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>0.836172</td>\n",
       "      <td>0.305353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12377406</th>\n",
       "      <td>117.651801</td>\n",
       "      <td>27.569128</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>2019-03-21</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>10.091276</td>\n",
       "      <td>0.564651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12377407</th>\n",
       "      <td>117.651801</td>\n",
       "      <td>27.569128</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>2019-03-21</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>7.186645</td>\n",
       "      <td>0.104363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12377408 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           longitude   latitude  operation_year  operation_month  \\\n",
       "0         112.499268  35.077713            2023                2   \n",
       "1         112.499268  35.077713            2023                2   \n",
       "2         112.499268  35.077713            2023                2   \n",
       "3         112.499268  35.077713            2023                2   \n",
       "4         112.499268  35.077713            2023                2   \n",
       "...              ...        ...             ...              ...   \n",
       "12377403  117.651801  27.569128            2019                3   \n",
       "12377404  117.651801  27.569128            2019                3   \n",
       "12377405  117.651801  27.569128            2019                3   \n",
       "12377406  117.651801  27.569128            2019                3   \n",
       "12377407  117.651801  27.569128            2019                3   \n",
       "\n",
       "          operation_day first_operation_date  year  month  day  \\\n",
       "0                     8           2023-02-08  2011      1    1   \n",
       "1                     8           2023-02-08  2011      1    2   \n",
       "2                     8           2023-02-08  2011      1    3   \n",
       "3                     8           2023-02-08  2011      1    4   \n",
       "4                     8           2023-02-08  2011      1    5   \n",
       "...                 ...                  ...   ...    ...  ...   \n",
       "12377403             21           2019-03-21  2023     12   27   \n",
       "12377404             21           2019-03-21  2023     12   28   \n",
       "12377405             21           2019-03-21  2023     12   29   \n",
       "12377406             21           2019-03-21  2023     12   30   \n",
       "12377407             21           2019-03-21  2023     12   31   \n",
       "\n",
       "          wt_cloud_optical_thickness  wt_cloud_mask_fraction  \n",
       "0                           1.887183                0.464000  \n",
       "1                           8.694333                0.972531  \n",
       "2                           8.330209                0.998417  \n",
       "3                           7.004502                0.999176  \n",
       "4                          10.417659                0.997777  \n",
       "...                              ...                     ...  \n",
       "12377403                    0.372230                0.180912  \n",
       "12377404                    0.049143                0.001069  \n",
       "12377405                    0.836172                0.305353  \n",
       "12377406                   10.091276                0.564651  \n",
       "12377407                    7.186645                0.104363  \n",
       "\n",
       "[12377408 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/anorawu/BFI Dropbox/Wanru Wu/Cloudseeding/data/炮台数据/processed_cloud_data_1.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['longitude','latitude','wt_cloud_optical_thickness','wt_cloud_mask_fraction','year','month','day']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112.499268</td>\n",
       "      <td>35.077713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4717</th>\n",
       "      <td>115.799438</td>\n",
       "      <td>25.602003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9434</th>\n",
       "      <td>100.015427</td>\n",
       "      <td>23.777602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14151</th>\n",
       "      <td>106.550948</td>\n",
       "      <td>26.853333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18868</th>\n",
       "      <td>100.179358</td>\n",
       "      <td>22.092365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12344389</th>\n",
       "      <td>112.767617</td>\n",
       "      <td>25.832370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12353823</th>\n",
       "      <td>121.511982</td>\n",
       "      <td>37.435467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12358540</th>\n",
       "      <td>116.555657</td>\n",
       "      <td>29.006848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12367974</th>\n",
       "      <td>121.218142</td>\n",
       "      <td>28.475891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12372691</th>\n",
       "      <td>117.651801</td>\n",
       "      <td>27.569128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2025 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           longitude   latitude\n",
       "0         112.499268  35.077713\n",
       "4717      115.799438  25.602003\n",
       "9434      100.015427  23.777602\n",
       "14151     106.550948  26.853333\n",
       "18868     100.179358  22.092365\n",
       "...              ...        ...\n",
       "12344389  112.767617  25.832370\n",
       "12353823  121.511982  37.435467\n",
       "12358540  116.555657  29.006848\n",
       "12367974  121.218142  28.475891\n",
       "12372691  117.651801  27.569128\n",
       "\n",
       "[2025 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['longitude','latitude']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(103.75, 44.5), (103.75, 45.0), (103.125, 44.5), (103.125, 45.0)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "import csv\n",
    "import warnings\n",
    "import os\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from geopy import distance\n",
    "\n",
    "\n",
    "def get_four_points(longitude, latitude):\n",
    "    lat1 = round(latitude * 2) / 2\n",
    "    lat2 = lat1 - 0.5 if lat1 > latitude else lat1 + 0.5\n",
    "\n",
    "    lon_list = np.arange(73.125, 135, 0.625).tolist()\n",
    "    lon1 = min(lon_list, key=lambda lon: abs(lon-longitude))\n",
    "    lon2 = lon1 - 0.625 if lon1 > longitude else lon1 + 0.625\n",
    "    \n",
    "    return [(lon1, lat1), (lon1, lat2), (lon2, lat1), (lon2, lat2)]\n",
    "\n",
    "print(get_four_points(103.44447,44.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.375"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "73.125+0.625*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
